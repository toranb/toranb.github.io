---
layout: post
title: "Adventures with Synthetic Data"
date:   2024-05-07 01:00:00
categories: blog archive
---

<p>After my <a href="https://www.youtube.com/watch?v=-iZIZHgHa5M">ElixirConf talk</a> I got deeper into fine tuning large language models. Not long after I found myself hunting for interesting uses cases and eventually landed in the realm of synthetic data for a few months.</p>

<p>I stumbled across <a href="https://edwarddonner.com/2024/01/11/fine-tune-llama-for-text-messages-part-1">this post from Edward Donner</a> about training a language model to write text messages in his likeness and the rest is history. I spent the bulk of my time cleaning the raw text message data in order to generate a quality dataset I could use to fine tune with.</p>

<p>The central theme of the talk is synthetic data generation but I touched on fine tuning with <a href="https://github.com/unslothai/unsloth">Unsloth</a>, Evaluation and even serving with <a href="https://github.com/elixir-nx/nx">Nx</a>. All credit to <a href="https://x.com/jon_durbin">Jon Durbin</a> for the DPO data generation technique mentioned in the talk. And finally, a shout out to <a href="https://paraxial.io/">Paraxial IO</a> for having me speak!</p>

<div style="padding-top: 20px; padding-bottom: 20px;">
  <div style="margin: auto; width: 90vw; height: 50vw; max-width: 768px; max-height: 432px">
    <iframe width="100%" height="100%" src="https://www.youtube.com/embed/R0VJIW0IYPo?si=_DC60mccDxzhyIHA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>
</div>

<p>The python source code for fine tuning with unsloth is on <a href="https://github.com/toranb/sloth">Github</a> for anyone interested. I also put the elixir code for the <a href="https://github.com/toranb/mistral-chat-f16">chat app</a> shown in the talk on Github.</p>
