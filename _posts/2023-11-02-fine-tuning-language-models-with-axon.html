---
layout: post
title: "Fine tuning language models with Axon"
date:   2023-11-02 01:00:00
categories: blog archive
---

<p>In 2023 I spent a lot of time at the intersection of software engineering and machine learning hoping to uncover the next great opportunity for automation. <a href="https://www.youtube.com/watch?v=-iZIZHgHa5M">My talk</a> at <a href="https://2023.elixirconf.com/">ElixirConf US</a> documented my attempt at simplifying the complex concepts in deep learning for those who feel overwhelmed by the technical aspects.</p>

<p>I started with <a href="https://blog.codinghorror.com/fizzbuzz-the-programmers-stairway-to-heaven/">FizzBuzz</a> because it was a problem most software engineers had some familiarity with which allowed me to subtly bridge the gap to more complex concepts. This widely known interview question was the perfect primer on the subject because underneath the diverse solutions was a well-understood classification problem that provided the optimal foundation for machine learning.</p>

<p>After the more introductory concepts I discussed fine-tuning pre-trained models for the specific task of text classification. I went into detail about my process including: creating a labeled dataset, transforming text into a form these models understand through tokenization and finally, fine tuning the model. I emphasized the critical role of data quality, the challenges that come with preparing or cleaning it, and the nuances of encoding text for machine learning models.</p>

<p>Toward the end of the talk I spoke about the trend towards off-the-shelf, open source models, and the opportunities for developers to upskill. For those eager to delve deeper, I recommend <a href="https://www.manning.com/books/grokking-deep-learning">Grokking Deep Learning</a> as an invaluable resource. In complete transparency this book inspired me to learn about neural networks and share it with others.</p>

<p>My goal was to make deep learning and model fine-tuning more approachable, especially for those in the Elixir community and more generally those new to machine learning. While this talk was presented at ElixirConf I actually think it's applicable to a much wider audience and hope others find it helpful.</p>

<p>Looking back, this journey has been about more than just acquiring knowledge; it's about sharing it, making the path less intimidating, and most importantly, showing how software engineering and machine learning collide to make way for innovation.</p>

<div style="padding-top: 20px; padding-bottom: 20px;">
  <div style="margin: auto; width: 90vw; height: 50vw; max-width: 768px; max-height: 432px">
    <iframe width="100%" height="100%" src="https://www.youtube.com/embed/-iZIZHgHa5M?si=QUUNTUtgAVDdfPfz" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
  </div>
</div>

<p>The source code is up on <a href="https://github.com/toranb/elixirconf2023">Github</a> for anyone who wanted to see a few of those examples in more detail. The full transcript for the talk can be downloaded <a href="/content/presentations/2024/finetune.txt">here</a>.</p>
